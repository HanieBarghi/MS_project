{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czck9VX7SNV8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import zipfile\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "from random import shuffle\n",
    "import cvxpy as cp\n",
    "import math\n",
    "from collections import Counter\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "import random\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso,LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sN73DJr-hUhM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# data generator\n",
    "\n",
    "def iid_data(d, D, n, sigma):\n",
    "    # matrix X generation\n",
    "    XX = np.zeros((n, d + 1))\n",
    "    for i in range(n):\n",
    "        XX[i][0] = 1.0\n",
    "        XX[i][1:] = np.random.normal(0, 1, d)\n",
    "\n",
    "    # D/d sparse w generation\n",
    "    w = [random.uniform(-1.0, 1.0) for i in range(D)]\n",
    "    w = np.array(w)\n",
    "    w = w / math.pow(LA.norm(w, 2), 2)\n",
    "    main_dim = set([])\n",
    "    while main_dim.__len__() < D:\n",
    "        main_dim.add(random.randint(1, d - 1))\n",
    "    main_dim = list(main_dim)\n",
    "    main_dim.sort()\n",
    "    ww = np.zeros((d + 1,))\n",
    "    for i in range(D):\n",
    "        ww[main_dim[i]] = w[i]\n",
    "\n",
    "    # error generation\n",
    "    error = np.random.normal(0, sigma, n)\n",
    "\n",
    "    # Y generation\n",
    "    YY = [np.matmul(np.transpose(ww), XX[i]) + error[i] for i in range(n)]\n",
    "    YY = np.array(YY)\n",
    "\n",
    "    return XX, YY, ww, main_dim,\n",
    "\n",
    "\n",
    "def partition(XX, YY, N):\n",
    "    X = []\n",
    "    Y = []\n",
    "    nn = int(XX.__len__() / N)\n",
    "    for i in range(N):\n",
    "        X.append(np.array(XX[i * nn:(i + 1) * nn]))\n",
    "        Y.append(np.array(YY[i * nn:(i + 1) * nn]))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8rRln2rmTt9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "def MSE(XX, YY, w):\n",
    "    return LA.norm(YY - np.matmul(XX, w), 2) / XX.__len__()\n",
    "\n",
    "def FMeasure(w, main_dim):\n",
    "    dim = []\n",
    "    for i in range(w.__len__()):\n",
    "        if w[i] != 0:\n",
    "            dim.append(i)\n",
    "    r = (set(dim) & set(main_dim)).__len__() / main_dim.__len__()\n",
    "    p = (set(dim) & set(main_dim)).__len__() / (dim.__len__() + 0.000000001)\n",
    "\n",
    "    return r,p, dim.__len__()/w.__len__()\n",
    "\n",
    "def similarity(Ws, main_dim):\n",
    "  dims = []\n",
    "  MV = [0 for i in range(d+1)]\n",
    "  for j in range(N):\n",
    "    dims.append([])\n",
    "    for i in range(d+1):\n",
    "      if Ws[j][i] != 0:\n",
    "        dims[j].append(i)\n",
    "        MV[i] += 1\n",
    "  a = [i for i in range(1001)]\n",
    "  for i in range(N):\n",
    "    a  = (set(a) & set(dims[i]))\n",
    "  print('\\n Intersection')\n",
    "  print('intersect size: ' + str(a.__len__()))\n",
    "  print((set(a) & set(main_dim)).__len__())\n",
    "\n",
    "\n",
    "def MJ(ws):\n",
    "  whole = []\n",
    "  output = []\n",
    "  for i in range(dims.__len__()):\n",
    "    for j in range(dims[i].__len__()):\n",
    "      whole.append(dims[i][j])\n",
    "\n",
    "  for i in range(20):\n",
    "      a = Counter(whole).most_common(1)[0][0]\n",
    "      output.append(a)\n",
    "      whole = list(filter((a).__ne__, whole))\n",
    "\n",
    "  print((set(output) & set(main_dim)).__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NiWU5FKmuJv",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# some functions need for the paper\n",
    "\n",
    "def generating_M(X):\n",
    "    print('generating covariance matrix is on progress')  \n",
    "    X = list(X)\n",
    "    for i in range(X.__len__()):\n",
    "        X[i] = list(X[i])\n",
    "    for row in X:\n",
    "            del row[0]\n",
    "    gama = []\n",
    "    # lambda_hat = [math.pow(10,i) * math.sqrt(math.log10(d)/( X.__len__())) for i in range(5)]\n",
    "    lambda_hat = [math.pow(10, i-10) for i in range(15)]\n",
    "    print('first for')\n",
    "    for i in range(d):\n",
    "        if i%10==0:\n",
    "          print(\"*\", end = '')\n",
    "        x = [row[i] for row in X]\n",
    "        XX = copy.deepcopy(X)\n",
    "        for row in XX:\n",
    "            del row[i]\n",
    "        XX = np.array(XX)\n",
    "        out = centralized(XX,x, lambda_hat, 10000)\n",
    "        gama.append(out[0])\n",
    "\n",
    "    C_hat = np.ones((d, d))\n",
    "    print('\\n senond for')\n",
    "    for i in range(d):\n",
    "        if i%10==0:\n",
    "          print(\"*\", end = '')      \n",
    "        for j in range(d):\n",
    "            if j < i:\n",
    "              C_hat[i][j] = -1 * gama[i][j]\n",
    "            elif i == j:\n",
    "                C_hat[i][j] = 1\n",
    "            else:\n",
    "              C_hat[i][j] = -1 * gama[i][j-1]\n",
    "    tai = []\n",
    "    print('\\n third for')\n",
    "    for i in range(d):\n",
    "        if i%10==0:\n",
    "          print(\"*\", end = '')\n",
    "        x = [row[i] for row in X]\n",
    "        XX = copy.deepcopy(X)\n",
    "        for j in XX:\n",
    "            del j[i]\n",
    "        a = np.transpose(x - np.matmul(XX, gama[i]))\n",
    "        a = np.matmul(a,x)\n",
    "        tai.append(a / X.__len__())\n",
    "    T_hat = np.diag(tai)\n",
    "    temp = np.matmul(T_hat, C_hat)\n",
    "    M = np.zeros((d+1,d+1))\n",
    "    for i in range(d+1):\n",
    "      for j in range(d+1):\n",
    "        if i==0 or j == 0:\n",
    "          if i == 0 and j == 0:\n",
    "            M[i][j] = 1.0\n",
    "        else:\n",
    "          M[i][j] = temp[i-1][j-1]\n",
    "\n",
    "    print('generating covariance matrix finished')  \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2hrqxCMnhd2",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "\n",
    "def centralized(X, Y, lambdas, itr):\n",
    "    lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "    parameters = {\n",
    "        'alpha': lambdas}\n",
    "    lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=10)\n",
    "    lasso_regressor.fit(X, Y)\n",
    "    lasso = Lasso(alpha=lasso_regressor.best_params_['alpha'], max_iter=itr)\n",
    "    lasso.fit(X, Y)\n",
    "    w = list(lasso.coef_)\n",
    "    return w, lasso.alpha\n",
    "\n",
    "def debiased(w, Y, X):\n",
    "    w_d = Y - np.matmul(X, w)\n",
    "    w_d = np.matmul(np.transpose(X), w_d)\n",
    "    pre = generating_M(X)\n",
    "    w_d = (np.matmul(pre, w_d)) / X.__len__()\n",
    "    w_d = w + w_d\n",
    "    return w_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9BbUazksksf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "d = 999\n",
    "D = 20\n",
    "n = 2000\n",
    "sigma = 0.00001\n",
    "X, Y, main_w, main_dim = iid_data(d, D, n, sigma)\n",
    "\n",
    "# save data in to a csv-file\n",
    "np.savetxt('X.csv', X, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)\n",
    "np.savetxt('Y.csv', Y, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)\n",
    "np.savetxt('main_w.csv', main_w, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)\n",
    "np.savetxt('main_dim.csv', main_dim, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFUJc8C9TW1Y",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# retrieve data\n",
    "\n",
    "X = genfromtxt('X.csv', delimiter=' ')\n",
    "Y = genfromtxt('Y.csv', delimiter=' ')\n",
    "main_w = genfromtxt('main_w.csv', delimiter=' ')\n",
    "main_dim = genfromtxt('main_dim.csv', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb-VvuTns0yk",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# centralized (Lasso)\n",
    "\n",
    "lambdas = [math.pow(10, i-10) for i in range(20)]\n",
    "w_c_l, alpha = centralized(X, Y, lambdas, 100000)\n",
    "\n",
    "# evaluation (MSE, R2, Recall=(Power), Precision(=1-FDR), sparsity)\n",
    "MSE_c_l = MSE(X, Y, w_c_l)\n",
    "\n",
    "f = [np.matmul(np.transpose(w_c_l), X[i]) for i in range(X.__len__())]\n",
    "R2_c_l = r2_score(Y, f)\n",
    "\n",
    "R_c_l, P_c_l, S_c_l = FMeasure(w_c_l, main_dim)\n",
    "\n",
    "# save results\n",
    "f = open(\"Centralized_Lasso_Results.txt\", \"a\")\n",
    "f.write('MSE: ' + str(MSE_c_l))\n",
    "f.write('\\nR2: ' + str(R2_c_l))\n",
    "f.write('\\nPrecision: ' + str(P_c_l))\n",
    "f.write('\\nRecall: ' + str(R_c_l))\n",
    "f.write('\\nSparsity: ' + str(S_c_l))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DbQYhedzy5A",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# centralized (de-biased Lasso)\n",
    "\n",
    "lambdas = [math.pow(10, i-10) for i in range(20)]\n",
    "w_c_d = debiased(w_c_l, Y, X)\n",
    "\n",
    "# evaluation (MSE, R2, Recall=(Power), Precision(=1-FDR), sparsity)\n",
    "MSE_c_d = MSE(X, Y, w_c_d)\n",
    "\n",
    "f = [np.matmul(np.transpose(w_c_d), X[i]) for i in range(X.__len__())]\n",
    "R2_c_d = r2_score(Y, f)\n",
    "\n",
    "P_c_d, R_c_d, S_c_d = FMeasure(w_c_d, main_dim)\n",
    "\n",
    "# save results\n",
    "f = open(\"Centralized_DBLasso_Results.txt\", \"a\")\n",
    "f.write('MSE: ' + str(MSE_c_d))\n",
    "f.write('\\nR2: ' + str(R2_c_d))\n",
    "f.write('\\nPrecision: ' + str(P_c_d))\n",
    "f.write('\\nRecall: ' + str(R_c_d))\n",
    "f.write('\\nSparsity: ' + str(S_c_d))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdMgxBVdTKxi",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# partitioning\n",
    "N = 20\n",
    "X_train, Y_train = partition(X, Y, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXsd-6DCTKxm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# de-centralized (Lasso)\n",
    "\n",
    "lambdas = [math.pow(10, i - 10) for i in range(20)]\n",
    "wls = []\n",
    "for i in range(N):\n",
    "    print('client ' + str(i) + ' is in progress.')\n",
    "    out = centralized(X_train[i], Y_train[i], lambdas, 100000)\n",
    "    wls.append(out[0])\n",
    "\n",
    "# evaluation (MSE, R2, Recall=(Power), Precision(=1-FDR), sparsity)\n",
    "MSE_d_l = 0\n",
    "R2_d_l = 0\n",
    "R_d_l = 0\n",
    "P_d_l = 0\n",
    "S_d_l = 0\n",
    "for i in range(N):\n",
    "    MSE_d_l += MSE(X_train[i], Y_train[i], wls[i])\n",
    "    f = [np.matmul(np.transpose(wls[i]), X_train[i][j]) for j in range(X_train[i].__len__())]\n",
    "    R2_d_l += r2_score(Y_train[i], f)\n",
    "    out = FMeasure(wls[i], main_dim)\n",
    "    R_d_l += out[0]\n",
    "    P_d_l += out[1]\n",
    "    S_d_l += out[2]\n",
    "MSE_d_l = MSE_d_l / N\n",
    "R2_d_l = R2_d_l / N\n",
    "R_d_l = R_d_l / N\n",
    "P_d_l = P_d_l / N\n",
    "S_d_l = S_d_l / N\n",
    "\n",
    "# save results\n",
    "f = open(\"De-centralized_Lasso_Results.txt\", \"a\")\n",
    "f.write('Averaged MSE: ' + str(MSE_d_l))\n",
    "f.write('\\nAveraged R2: ' + str(R2_d_l))\n",
    "f.write('\\nAveraged Precision: ' + str(P_d_l))\n",
    "f.write('\\nAveraged Recall: ' + str(R_d_l))\n",
    "f.write('\\nAveraged Sparsity: ' + str(S_d_l))\n",
    "f.close()\n",
    "\n",
    "wls = np.array(wls)\n",
    "np.savetxt('wls.csv', wls, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyM0CcSWTKxo",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# de-centralized (de-biased Lasso)\n",
    "\n",
    "lambdas = [math.pow(10, i-10) for i in range(20)]\n",
    "wds = []\n",
    "for i in range(N):\n",
    "  print('client ' + str(i) + ' is in progress.')\n",
    "  out = debiased(wls[i], Y_train[i], X_train[i])\n",
    "  wds.append(out[0])\n",
    "\n",
    "\n",
    "# evaluation (MSE, R2, Recall=(Power), Precision(=1-FDR), sparsity)\n",
    "MSE_d_d = 0\n",
    "R2_d_d = 0\n",
    "R_d_d = 0\n",
    "P_d_d = 0\n",
    "S_d_d = 0\n",
    "for i in range(N):\n",
    "  MSE_d_d += MSE(X_train[i], Y_train[i], wds[i])\n",
    "  f =  np.matmul(np.transpose(wds[i]), X_train[i][j]) for j in range(X_train[i].__len__())]\n",
    "  R2_d_d += r2_score(Y_train[i], f)\n",
    "  out = FMeasure(wds[i], main_dim)\n",
    "  R_d_d += out[0]\n",
    "  P_d_d += out[1]\n",
    "  S_d_d += out[2]\n",
    "MSE_d_d = MSE_d_d / N\n",
    "R2_d_d = R2_d_d / N\n",
    "R_d_d = R_d_d / N\n",
    "P_d_d = P_d_d / N\n",
    "S_d_d = S_d_d / N\n",
    "\n",
    "# save results\n",
    "f = open(\"De-centralized_DBLasso_Results.txt\", \"a\")\n",
    "f.write('Averaged MSE: ' + str(MSE_d_d))\n",
    "f.write('\\nAveraged R2: ' + str(R2_d_d))\n",
    "f.write('\\nAveraged Precision: ' + str(P_d_d))\n",
    "f.write('\\nAveraged Recall: ' + str(R_d_d))\n",
    "f.write('\\nAveraged Sparsity: ' + str(S_d_d))\n",
    "f.close()\n",
    "\n",
    "wds = np.array(wds)\n",
    "np.savetxt('wds.csv', wds, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "colab": {
   "name": "code.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
